{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f7f354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install gymnasium renderlab\n",
    "# !pip install opencv-python\n",
    "# !pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74465ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "%config NotebookApp.iopub_msg_rate_limit=10000\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d3f34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19]]\n"
     ]
    }
   ],
   "source": [
    "#visualise maze:\n",
    "rfpMaze = [\"SFFF\", \"FHHH\", \"FFFF\", \"HFHF\", \"FFGF\"]\n",
    "maze1 = [\"SFFH\", \"FHHF\", \"FHFG\", \"FFFH\", \"HFHH\"]\n",
    "\n",
    "desc = rfpMaze\n",
    "mazeSize = [len(desc),len(desc[0])]\n",
    "\n",
    "statePositions = [[] for _ in range(mazeSize[0])]\n",
    "stateNum = 0\n",
    "for i in range(mazeSize[0]):\n",
    "    for j in range(mazeSize[1]):\n",
    "        statePositions[i].append(stateNum)\n",
    "        stateNum += 1\n",
    "        \n",
    "\n",
    "        \n",
    "giftState = -1\n",
    "gift_found = False\n",
    "for i in range(len(desc)):\n",
    "    if gift_found:\n",
    "        break\n",
    "    for j in range(len(desc[i])):\n",
    "        giftState += 1\n",
    "        if desc[i][j] == 'G':\n",
    "            gift_found = True\n",
    "            break\n",
    "            \n",
    "print(giftState)\n",
    "print(statePositions)\n",
    "\n",
    "env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x5\", is_slippery=False, render_mode=\"human\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b980268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qTable_1 = {}\n",
    "def resetTable():\n",
    "    global qTable_1\n",
    "    qTable_1 = {}\n",
    "    for i in range(mazeSize[0]*mazeSize[1]):\n",
    "        qTable_1[i] = [0,0,0,0] \n",
    "    global currentState\n",
    "    currentState = 0\n",
    "    \n",
    "def getPosition(state):\n",
    "    for i in range(len(statePositions)):\n",
    "        for j in range(len(statePositions[i])):\n",
    "            if statePositions[i][j] == state:\n",
    "                return i, j\n",
    "            \n",
    "def calcReward(state, nextState):\n",
    "    y1, x1 = getPosition(state)\n",
    "    y2, x2 = getPosition(nextState)\n",
    "    y3, x3 = getPosition(giftState)\n",
    "    \n",
    "    currentDist = (((y3 - y1)**2)+((x3 - x1)**2))**0.5\n",
    "    nextDist = (((y3 - y2)**2)+((x3 - x2)**2))**0.5\n",
    "    \n",
    "    changeInDist = currentDist-nextDist\n",
    "    return changeInDist/2\n",
    "\n",
    "def calcPossibleMoves(state):\n",
    "    global qTable_1\n",
    "    possibleMoves = []\n",
    "    \n",
    "    if state == 0:\n",
    "        return [1,2]\n",
    "    \n",
    "    if (state+1) % mazeSize[1] != 0:\n",
    "        possibleMoves.append(2)\n",
    "        \n",
    "    if (state+1) % mazeSize[1] != 1:\n",
    "        possibleMoves.append(0)\n",
    "        \n",
    "    if state > (mazeSize[1]-1):\n",
    "        possibleMoves.append(3)\n",
    "    \n",
    "    if state < ((mazeSize[0] * mazeSize[1]) - mazeSize[1]):\n",
    "        possibleMoves.append(1)\n",
    "        \n",
    "    return possibleMoves\n",
    "\n",
    "def nextStep(state):\n",
    "    global qTable_1\n",
    "    possMoves = calcPossibleMoves(state)\n",
    "    \n",
    "    if random.random() < epsilonValue:\n",
    "        nextMove = random.choice(possMoves)\n",
    "    else:\n",
    "        qValues = {}\n",
    "        for move in possMoves:\n",
    "            qValues[move] = qTable_1[state][move]\n",
    "\n",
    "        maxValue = max(qValues.values())\n",
    "        minValue = min(qValues.values())\n",
    "        count_max = sum(1 for value in qValues.values() if value == maxValue)\n",
    "        count_min = sum(1 for value in qValues.values() if value == minValue)\n",
    "\n",
    "        if count_max > 1 and count_max < len(possMoves):\n",
    "            nextMove = random.choice([move for move in possMoves if qValues[move] != minValue])\n",
    "        elif count_max == len(possMoves):\n",
    "            nextMove = random.choice(possMoves)\n",
    "        else:\n",
    "            nextMove = max(qValues, key=qValues.get)\n",
    "    return nextMove\n",
    "\n",
    "def pathFound():\n",
    "    currentState = 0\n",
    "    for i in range(mazeSize[0]*mazeSize[1]-1):\n",
    "        bestDirection = None\n",
    "        if max(qTable_1[currentState]) > 0:\n",
    "            bestDirection = qTable_1[currentState].index(max(qTable_1[currentState]))\n",
    "        newState = 0\n",
    "        if bestDirection == 0 and 0 in calcPossibleMoves(currentState):\n",
    "            newState = currentState - 1\n",
    "        elif bestDirection == 1 and 1 in calcPossibleMoves(currentState):\n",
    "            newState = currentState + mazeSize[1]\n",
    "        elif bestDirection == 2 and 2 in calcPossibleMoves(currentState):\n",
    "            newState = currentState + 1\n",
    "        elif bestDirection == 3 and 3 in calcPossibleMoves(currentState):\n",
    "            newState = currentState - mazeSize[1]\n",
    "\n",
    "        if newState == giftState:\n",
    "            return True\n",
    "        currentState = newState\n",
    "    return False\n",
    "\n",
    "timesVisited = {}\n",
    "def resetVisited():\n",
    "    global timesVisited\n",
    "    timesVisited = {}\n",
    "    for i in range(mazeSize[0]*mazeSize[1]):\n",
    "        timesVisited[i] = 0\n",
    "\n",
    "def updateTable_qLearning(direction, nextState, reward):\n",
    "    global qTable_1\n",
    "    global currentState\n",
    "    didConverge = False\n",
    "    updated = qTable_1[currentState][direction] + alpha*(reward + (max(qTable_1[nextState])) - qTable_1[currentState][direction])\n",
    "    changeInQ = round(abs(qTable_1[currentState][direction] - updated),5)\n",
    "    if changeInQ < convergenceThresh:\n",
    "        if changeInQ > 0 and pathFound():\n",
    "            didConverge = True\n",
    "    qTable_1[currentState][direction] = updated\n",
    "    timesVisited[currentState] += 1\n",
    "    currentState = nextState\n",
    "    return didConverge, changeInQ\n",
    "\n",
    "def updateTable_sarsa(direction, nextState, reward):\n",
    "    global qTable_1\n",
    "    global currentState\n",
    "    didConverge = False\n",
    "    nextDirection = nextStep(nextState)\n",
    "    updated = qTable_1[currentState][direction] + alpha*(reward + (qTable_1[nextState][nextDirection]) - qTable_1[currentState][direction])\n",
    "    changeInQ = round(abs(qTable_1[currentState][direction] - updated),5)\n",
    "    if changeInQ < convergenceThresh:\n",
    "        if changeInQ > 0 and pathFound():\n",
    "            didConverge = True\n",
    "    qTable_1[currentState][direction] = updated\n",
    "    timesVisited[currentState] += 1\n",
    "    currentState = nextState\n",
    "    return didConverge, changeInQ, nextDirection\n",
    "\n",
    "def updateTable_monteCarlo(steps, totalReward):\n",
    "    global qTable_1\n",
    "    global currentState\n",
    "    global direction\n",
    "    minChangeInQ = 0\n",
    "    didConverge = False\n",
    "    avgReward = totalReward/len(steps)\n",
    "    for i in range(len(steps)):\n",
    "        updated = qTable_1[steps[i][0]][steps[i][1]] + alpha*(avgReward-qTable_1[steps[i][0]][steps[i][1]])\n",
    "        changeInQ = round(abs(qTable_1[currentState][direction] - updated),5)\n",
    "        if i == 0:\n",
    "            minChangeInQ = changeInQ\n",
    "        elif changeInQ < minChangeInQ and changeInQ != 0:\n",
    "            minChangeInQ = changeInQ\n",
    "        if changeInQ < convergenceThresh:\n",
    "            if changeInQ > 0 and pathFound():\n",
    "                didConverge = True\n",
    "        qTable_1[steps[i][0]][steps[i][1]] = updated\n",
    "    timesVisited[currentState] += 1\n",
    "    return didConverge, minChangeInQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b6b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilonValue = 0.35\n",
    "alpha = 0.65\n",
    "convergenceThresh = 0.01\n",
    "revistPenalty = -0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93fee2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q LEARNING-----------------------------------------------------------------------\n",
    "\n",
    "def qLearning(trialType, maxEpisodes, currentTrial):\n",
    "    global currentState\n",
    "    global revisitPenalty\n",
    "    global totalTrials\n",
    "    global totalTime_start\n",
    "    \n",
    "    currentState = 0\n",
    "    currentEpisode = 1\n",
    "    converged = False\n",
    "    \n",
    "    resetVisited()\n",
    "    resetTable()\n",
    "    env.reset()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while currentEpisode <= maxEpisodes:\n",
    "        if converged:\n",
    "            break\n",
    "\n",
    "        direction = nextStep(currentState)\n",
    "        nextState, reward, terminated, truncated, info = env.step(direction)\n",
    "        \n",
    "        if trialType == 0:\n",
    "            if terminated:\n",
    "                if not reward < 1:\n",
    "                    reward = 10\n",
    "        elif trialType == 1:\n",
    "            if terminated:\n",
    "                if reward < 1:\n",
    "                    reward = -1\n",
    "                else:\n",
    "                    reward = 10\n",
    "            if not terminated:\n",
    "                reward = calcReward(currentState, nextState)\n",
    "                if timesVisited[nextState] > 0:\n",
    "                    reward += revistPenalty*timesVisited[nextState]\n",
    "\n",
    "        converged, changeInQ = updateTable_qLearning(direction, nextState, reward)\n",
    "\n",
    "        if terminated or truncated or converged:\n",
    "            observation, info = env.reset()\n",
    "            currentState = 0\n",
    "            if not converged:\n",
    "                currentEpisode += 1\n",
    "                resetVisited()\n",
    "\n",
    "\n",
    "        if converged:\n",
    "            end_time = time.time()\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(\"Trial: \" + 'Q-Learning, ' + 'trialType '+ str(trialType) + ', Trial ' + str(currentTrial) + \"/\" + str(totalTrials))\n",
    "        print(\"Episode: \" + str(currentEpisode) + \"/\" + str(maxEpisodes))\n",
    "        print(\"Trial Time: \" + str(round(time.time()-start_time, 3)) + \" sec\")\n",
    "        print(\"Total Time: \" + str(round((time.time()-totalTime_start)/60, 3)) + \" min\")\n",
    "        print(\"Q-Table:\")\n",
    "        for i in range(len(qTable_1)):\n",
    "            print(str(i) + \": \" + str(qTable_1[i]))\n",
    "        print(\"change in Q: \" + str(changeInQ))\n",
    "        \n",
    "    duration = 0\n",
    "    if converged:\n",
    "        duration = end_time - start_time\n",
    "        print(str(round(duration, 3)) + \" seconds to converge\")\n",
    "    else:\n",
    "        duration = None\n",
    "        print(\"No convergence\")\n",
    "        \n",
    "    return currentEpisode, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c94f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARSA-----------------------------------------------------------------------\n",
    "\n",
    "def sarsa(trialType, maxEpisodes, currentTrial):\n",
    "    global currentState\n",
    "    global revisitPenalty\n",
    "    global totalTrials\n",
    "    global totalTime_start\n",
    "    \n",
    "    currentState = 0\n",
    "    currentEpisode = 1\n",
    "    converged = False\n",
    "    startOfEpisode = True\n",
    "    direction = None\n",
    "\n",
    "    resetVisited()\n",
    "    resetTable()\n",
    "    env.reset()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while currentEpisode <= maxEpisodes:\n",
    "        if converged:\n",
    "            break\n",
    "\n",
    "        if startOfEpisode:\n",
    "            direction = nextStep(currentState)\n",
    "            startOfEpisode = False\n",
    "        nextState, reward, terminated, truncated, info = env.step(direction)\n",
    "\n",
    "        if trialType == 0:\n",
    "            if terminated:\n",
    "                if not reward < 1:\n",
    "                    reward = 10\n",
    "        elif trialType == 1:\n",
    "            if terminated:\n",
    "                if reward < 1:\n",
    "                    reward = -1\n",
    "                else:\n",
    "                    reward = 10\n",
    "            if not terminated:\n",
    "                reward = calcReward(currentState, nextState)\n",
    "                if timesVisited[nextState] > 0:\n",
    "                    reward += revistPenalty*timesVisited[nextState]\n",
    "\n",
    "        converged, changeInQ, nextDirection = updateTable_sarsa(direction, nextState, reward)\n",
    "        direction = nextDirection\n",
    "\n",
    "        if terminated or truncated or converged:\n",
    "            observation, info = env.reset()\n",
    "            currentState = 0\n",
    "            if not converged:\n",
    "                currentEpisode += 1\n",
    "                startOfEpisode = False\n",
    "                resetVisited()\n",
    "\n",
    "\n",
    "        if converged:\n",
    "            end_time = time.time()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"trial: \" + 'SARSA, ' + 'trialType '+ str(trialType) + ', Trial ' + str(currentTrial) + \"/\" + str(totalTrials))\n",
    "        print(\"Episode: \" + str(currentEpisode) + \"/\" + str(maxEpisodes))\n",
    "        print(\"Trial Time: \" + str(round(time.time()-start_time, 3)) + \" sec\")\n",
    "        print(\"Total Time: \" + str(round((time.time()-totalTime_start)/60, 3)) + \" min\")\n",
    "        print(\"Q-Table:\")\n",
    "        for i in range(len(qTable_1)):\n",
    "            print(str(i) + \": \" + str(qTable_1[i]))\n",
    "        print(\"change in Q: \" + str(changeInQ))\n",
    "\n",
    "    duration = 0\n",
    "    if converged:\n",
    "        duration = end_time - start_time\n",
    "        print(str(round(duration, 3)) + \" seconds to converge\")\n",
    "    else:\n",
    "        duration = None\n",
    "        print(\"No convergence\")\n",
    "        \n",
    "    return currentEpisode, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db2d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo -----------------------------------------------------------------------\n",
    "\n",
    "def monteCarlo(trialType, maxEpisodes, currentTrial):\n",
    "    global currentState\n",
    "    global revisitPenalty\n",
    "    global direction\n",
    "    global totalTrials\n",
    "    global totalTime_start\n",
    "    \n",
    "    currentEpisode = 1\n",
    "    converged = False\n",
    "\n",
    "    episodeSteps = []\n",
    "    totalReward = 0\n",
    "\n",
    "    resetVisited()\n",
    "    resetTable()\n",
    "    env.reset()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while currentEpisode <= maxEpisodes:\n",
    "        global currentState\n",
    "        if converged:\n",
    "            break\n",
    "\n",
    "        direction = nextStep(currentState)\n",
    "        episodeSteps.append([currentState, direction])\n",
    "        nextState, reward, terminated, truncated, info = env.step(direction)\n",
    "\n",
    "        if trialType == 0:\n",
    "            if terminated:\n",
    "                if not reward < 1:\n",
    "                    reward = 10\n",
    "        elif trialType == 1:\n",
    "            if terminated:\n",
    "                if reward < 1:\n",
    "                    reward = -1\n",
    "                else:\n",
    "                    reward = 10\n",
    "            if not terminated:\n",
    "                reward = calcReward(currentState, nextState)\n",
    "                if timesVisited[nextState] > 0:\n",
    "                    reward += revistPenalty*timesVisited[nextState]\n",
    "\n",
    "        totalReward += reward\n",
    "        currentState = nextState\n",
    "\n",
    "        changeQ = 0\n",
    "        if terminated or truncated:\n",
    "            observation, info = env.reset()\n",
    "            converged, changeInQ = updateTable_monteCarlo(episodeSteps, totalReward)\n",
    "            changeQ = changeInQ\n",
    "            episodeSteps = []\n",
    "            currentState = 0\n",
    "            currentEpisode += 1\n",
    "            resetVisited()\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "        print(\"trial: \" + 'Monte Carlo, ' + 'trialType '+ str(trialType) + ', Trial ' + str(currentTrial) + \"/\" + str(totalTrials))\n",
    "        print(\"Episode: \" + str(currentEpisode) + \"/\" + str(maxEpisodes))\n",
    "        print(\"Current Path: \" + str(episodeSteps))\n",
    "        print(\"Trial Time: \" + str(round(time.time()-start_time, 3)) + \" sec\")\n",
    "        print(\"Total Time: \" + str(round((time.time()-totalTime_start)/60, 3)) + \" min\")\n",
    "        print(\"Q-Table:\")\n",
    "        for i in range(len(qTable_1)):\n",
    "            print(str(i) + \": \" + str(qTable_1[i]))\n",
    "        print(\"change in Q: \" + str(changeQ))\n",
    "\n",
    "        if converged:\n",
    "            end_time = time.time()\n",
    "            observation, info = env.reset()\n",
    "\n",
    "    duration = 0\n",
    "    if converged:\n",
    "        duration = end_time - start_time\n",
    "        print(str(round(duration, 3)) + \" seconds to converge\")\n",
    "    else:\n",
    "        duration = None\n",
    "        print(\"No convergence\")\n",
    "        \n",
    "    return currentEpisode, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14b9b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial types: \n",
    "#     0: only +10 reward for reaching present\n",
    "    \n",
    "#     1: gets +10 for reaching present\n",
    "#        possitive reward equal to 1/2 change in distance towards the present\n",
    "#        negative reward equal to 1/2 change in distance away from present\n",
    "#        negative reward for revisiting spaces equal to -0.25 * times visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90451749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: SARSA, trialType 1, Trial 6/6\n",
      "Episode: 22/2000\n",
      "Trial Time: 39.82 sec\n",
      "Total Time: 166.573 min\n",
      "Q-Table:\n",
      "0: [0.5952885117064284, 0.9811749807989125, -0.12270608310031522, 0.8956612521695743]\n",
      "1: [0.22013825253500993, -0.8775, -0.36848740676025143, 0]\n",
      "2: [0, -0.8775, 0, 0]\n",
      "3: [0, 0, 0, 0]\n",
      "4: [0, 0.5454182019653259, -0.8775, -0.4590769020968186]\n",
      "5: [0, 0, 0, 0]\n",
      "6: [0, 0, 0, 0]\n",
      "7: [0, 0, 0, 0]\n",
      "8: [0, -0.65, 0.17925369233769334, -1.253444244383545]\n",
      "9: [-0.3485832985497473, -0.08731787329669366, 0.06511632800091147, -0.957125]\n",
      "10: [-0.6617220926874317, -0.8775, 0.2076504877063877, -0.65]\n",
      "11: [0, 0.3707367771616994, 0, 0]\n",
      "12: [0, 0, 0, 0]\n",
      "13: [-0.8775, 0.13461940777125592, -0.8775, -0.26262695966552335]\n",
      "14: [0, 0, 0, 0]\n",
      "15: [-0.65, 4.3355266897075815, 0, -0.2559859397206615]\n",
      "16: [0, 0, 0, 0]\n",
      "17: [0, 0, 6.5, 0]\n",
      "18: [0, 0, 0, 0]\n",
      "19: [8.775, 0, 0, -0.5340468699552741]\n",
      "change in Q: 0.00458\n",
      "39.819 seconds to converge\n"
     ]
    }
   ],
   "source": [
    "maxEpisodes = 2000\n",
    "algs = ['Q-Learning', 'SARSA', 'Monte Carlo']\n",
    "trials = [0,1]\n",
    "totalTrials = 6\n",
    "trialData = pd.DataFrame()\n",
    "totalTime_start = time.time()\n",
    "\n",
    "for alg in algs:\n",
    "    for typ in trials:\n",
    "        if alg == algs[0]:\n",
    "            episodes1, duration1 = qLearning(typ, maxEpisodes, 1)\n",
    "            episodes2, duration2 = qLearning(typ, maxEpisodes, 2)\n",
    "            episodes3, duration3 = qLearning(typ, maxEpisodes, 3)\n",
    "            episodes4, duration4 = qLearning(typ, maxEpisodes, 4)\n",
    "            episodes5, duration5 = qLearning(typ, maxEpisodes, 5)\n",
    "            episodes6, duration6 = qLearning(typ, maxEpisodes, 6)\n",
    "        elif alg == algs[1]:\n",
    "            episodes1, duration1 = sarsa(typ, maxEpisodes, 1)\n",
    "            episodes2, duration2 = sarsa(typ, maxEpisodes, 2)\n",
    "            episodes3, duration3 = sarsa(typ, maxEpisodes, 3)\n",
    "            episodes4, duration4 = sarsa(typ, maxEpisodes, 4)\n",
    "            episodes5, duration5 = sarsa(typ, maxEpisodes, 5)\n",
    "            episodes6, duration6 = sarsa(typ, maxEpisodes, 6)\n",
    "        row = pd.DataFrame({'alg':alg,\n",
    "                            'trialType': typ,\n",
    "                            'trial-1_episodes':episodes1,\n",
    "                            'trial-1_duration': duration1,\n",
    "                            'trial-2_episodes':episodes2,\n",
    "                            'trial-2_duration': duration2,\n",
    "                            'trial-3_episodes':episodes3,\n",
    "                            'trial-3_duration': duration3,\n",
    "                            'trial-4_episodes':episodes4,\n",
    "                            'trial-4_duration': duration4,\n",
    "                            'trial-5_episodes':episodes5,\n",
    "                            'trial-5_duration': duration5,\n",
    "                            'trial-6_episodes':episodes6,\n",
    "                            'trial-6_duration': duration6,}, index=[0])\n",
    "        trialData = pd.concat([trialData, row], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e82da0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, {'prob': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "345a586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b95f0a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg</th>\n",
       "      <th>trialType</th>\n",
       "      <th>trial-1_episodes</th>\n",
       "      <th>trial-1_duration</th>\n",
       "      <th>trial-2_episodes</th>\n",
       "      <th>trial-2_duration</th>\n",
       "      <th>trial-3_episodes</th>\n",
       "      <th>trial-3_duration</th>\n",
       "      <th>trial-4_episodes</th>\n",
       "      <th>trial-4_duration</th>\n",
       "      <th>trial-5_episodes</th>\n",
       "      <th>trial-5_duration</th>\n",
       "      <th>trial-6_episodes</th>\n",
       "      <th>trial-6_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q-Learning</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>217.120624</td>\n",
       "      <td>305</td>\n",
       "      <td>444.221955</td>\n",
       "      <td>325</td>\n",
       "      <td>450.969038</td>\n",
       "      <td>599</td>\n",
       "      <td>867.126607</td>\n",
       "      <td>403</td>\n",
       "      <td>592.907048</td>\n",
       "      <td>462</td>\n",
       "      <td>646.499772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q-Learning</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>32.053080</td>\n",
       "      <td>17</td>\n",
       "      <td>25.527438</td>\n",
       "      <td>31</td>\n",
       "      <td>58.346834</td>\n",
       "      <td>25</td>\n",
       "      <td>39.057369</td>\n",
       "      <td>15</td>\n",
       "      <td>22.541911</td>\n",
       "      <td>14</td>\n",
       "      <td>22.535672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SARSA</td>\n",
       "      <td>0</td>\n",
       "      <td>898</td>\n",
       "      <td>1375.606988</td>\n",
       "      <td>1227</td>\n",
       "      <td>1832.030497</td>\n",
       "      <td>1143</td>\n",
       "      <td>1800.343550</td>\n",
       "      <td>437</td>\n",
       "      <td>669.268452</td>\n",
       "      <td>293</td>\n",
       "      <td>440.907421</td>\n",
       "      <td>107</td>\n",
       "      <td>168.510237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARSA</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>34.557689</td>\n",
       "      <td>30</td>\n",
       "      <td>60.839801</td>\n",
       "      <td>9</td>\n",
       "      <td>18.521327</td>\n",
       "      <td>30</td>\n",
       "      <td>54.327219</td>\n",
       "      <td>38</td>\n",
       "      <td>74.602866</td>\n",
       "      <td>22</td>\n",
       "      <td>39.818830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alg  trialType  trial-1_episodes  trial-1_duration  \\\n",
       "0  Q-Learning          0               152        217.120624   \n",
       "1  Q-Learning          1                18         32.053080   \n",
       "2       SARSA          0               898       1375.606988   \n",
       "3       SARSA          1                18         34.557689   \n",
       "\n",
       "   trial-2_episodes  trial-2_duration  trial-3_episodes  trial-3_duration  \\\n",
       "0               305        444.221955               325        450.969038   \n",
       "1                17         25.527438                31         58.346834   \n",
       "2              1227       1832.030497              1143       1800.343550   \n",
       "3                30         60.839801                 9         18.521327   \n",
       "\n",
       "   trial-4_episodes  trial-4_duration  trial-5_episodes  trial-5_duration  \\\n",
       "0               599        867.126607               403        592.907048   \n",
       "1                25         39.057369                15         22.541911   \n",
       "2               437        669.268452               293        440.907421   \n",
       "3                30         54.327219                38         74.602866   \n",
       "\n",
       "   trial-6_episodes  trial-6_duration  \n",
       "0               462        646.499772  \n",
       "1                14         22.535672  \n",
       "2               107        168.510237  \n",
       "3                22         39.818830  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trialData = trialData.drop(trialData.index[[4, 5]], axis=0)\n",
    "trialData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6649b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialData.to_csv('trialData_set7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a80f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
